common:
    name: "my_config"
    task: "binary" # binary, multiclass, regression
    metrics:
        - f1
        - roc_auc
        - "recall@k;k=0.01"
        - "precision@k;k=0.01"
        - "ap;average=micro" # average_precision_score
        - "ap;average=weighted" # average_precision_score
        - "f1;average=binary"
    main_metric: roc_auc
    model_dir: "/home/gleb/models" # пути сохранения обученных моделей
    skip_cols: []
    selected_models:
        - catboost
        - lightgbm
        - xgboost
        - random_forest
        - lightautoml
        - tabnet

split_data:
    test_rate: 0.2
    validation_rate: 0.2 # если не казан valid_path
    binary_threshold: 0.5 # доля положительных классов относительно негативных
    stratified_split: true # стратифицированное разбиение

sampling: # начальное сэмплирование данных
    use_sampling: true   # Если поставить false, то сэмплирование делать не будем
    train_sample_size: 100000 # размер тренировочной выборки
    validation_sample_size: 100000 # размер валидационной выборки
    sample_seed: 42 # seed для сэмплирования
    balanced_sampling: true # только для классификации
    positive_rate: 0.5 # только для бинарной классификации

train:
    verbose: true
    n_folds: 3 # количество фолдов для кросс-валидации

columns:
    all_features_file: "/home/gleb/artifacts_preprocessing/final_feature_list.txt"
    category_features_file: "/home/gleb/artifacts_preprocessing/final_categorical_list.txt"
    target_col: "target"
    index_cols: ["epk_id"]

data_source: # данные уже предобработаны и не содержат пропусков, категориальные признаки закодированы в целые числа
    train_path: "/home/gleb/data/results/train_for_sota.parquet"
    valid_path: "/home/gleb/data/results/test_for_sota.parquet"

calibration:
    use_calibration: true # калибровка модели (только для бинарной классификации)
    calibration_type: "betacal" # betacal, isotonic

# Настройки специфичные для каждой модели
models:
    catboost:
        n_folds: 3
        use_custom_hyperparameters: false
        hyperparameters:
            depth: 10
            learning_rate: 0.01
            l2_leaf_reg: 3
            random_strength: 1
            bagging_temperature: 1
    lightgbm:
        n_folds: 3
        use_custom_hyperparameters: false
        hyperparameters:
            depth: 10
            learning_rate: 0.01
            l2_leaf_reg: 3
            random_strength: 1
            bagging_temperature: 1
    xgboost:
        n_folds: 3
        use_custom_hyperparameters: false
        hyperparameters:
            depth: 10
            learning_rate: 0.01
            l2_leaf_reg: 3
            random_strength: 1
            bagging_temperature: 1
    random_forest:
        n_folds: 3
        use_custom_hyperparameters: false
        hyperparameters:
            depth: 10
            learning_rate: 0.01
            l2_leaf_reg: 3
            random_strength: 1
    tabnet:
        n_folds: 1
        use_custom_hyperparameters: true
        hyperparameters:
            cat_emb_dim: 4 # размерность эмбеддингов для категориальных признаков, диапазон [1-16]
            n_steps: 4 # количество шагов в TabNet, диапазон [3-10]
            hidden_dim: 16 # размерность скрытого слоя, диапазон [8-128]
            decision_dim: 8 # размерность решающего слоя, диапазон [4-64]
            n_glu_layers: 3 # количество GLU слоев, диапазон [2-4]
            dropout: 0.1 # вероятность дропаута, диапазон [0.1-0.9]
            gamma: 1.5 # коэффициент затухания для масок внимания, диапазон [1.0-2.0]
            lambda_sparse: 0.0001 # коэффициент регуляризации разреженности, диапазон [0-0.01]
            virtual_batch_size: 128 # размер виртуального батча, диапазон [128-4096]
            momentum: 0.9 # параметр momentum для BatchNorm, диапазон [0.6-0.98]
            batch_size: 1024 # размер батча для обучения, диапазон [256-32768]
            epochs: 50 # количество эпох обучения, диапазон {20, 50, 100, 200, ...}
            learning_rate: 0.01 # скорость обучения, диапазон [0.001-0.025]
            early_stopping_patience: 5 # количество эпох без улучшения до остановки обучения
            weight_decay: 1e-5 # L2-регуляризация для оптимизатора
            scale_numerical: true # масштабировать ли числовые признаки
            scale_method: "standard" # метод масштабирования числовых признаков (standard, minmax, quantile, binning)
            n_bins: 10 # количество бинов для binning
            device: cuda # устройство для обучения (cuda/cpu)
            verbose: true # выводить ли прогресс обучения
            num_workers: 0 # количество worker-процессов для DataLoader (0 - однопроцессный режим)
            random_state: 42 # seed для генерации случайных чисел
    cemlp:
        n_folds: 1
        use_custom_hyperparameters: true
        hyperparameters:
            cat_emb_dim: 4 # размерность эмбеддингов для категориальных признаков, диапазон [2-16]
            hidden_dims: [64, 32] # список размерностей скрытых слоев, например [32, 16], значения 8-256
            activation: relu # функция активации: relu, leaky_relu, selu, elu, gelu, swish, prelu
            dropout: 0.1 # вероятность дропаута, диапазон [0.0-0.9]
            feature_dropout: 0.0 # dropout для входных признаков (feature-wise), диапазон [0.0-0.5]
            batch_norm: true # использовать batch normalization: true/false
            layer_norm: false # использовать layer normalization: true/false
            initialization: he_normal # метод инициализации весов: he_normal, he_uniform, xavier_normal, xavier_uniform
            leaky_relu_negative_slope: 0.1 # отрицательный наклон для leaky_relu, диапазон [0.01-0.3]
            dynamic_emb_size: false # использовать динамический размер эмбеддинга: true/false
            min_emb_dim: 2 # min размер эмбеддинга при dynamic_emb_size, диапазон [1-16]
            max_emb_dim: 16 # max размер эмбеддинга при dynamic_emb_size, диапазон [2-64]
            batch_size: 1024 # размер батча, диапазон [32-4096]
            epochs: 50 # количество эпох, диапазон [10-200]
            learning_rate: 0.001 # скорость обучения, диапазон [0.0001-0.01]
            momentum: 0.9 # momentum для BatchNorm, диапазон [0.6-0.99]
            weight_decay: 1e-5 # L2-регуляризация, диапазон [0-0.001]
            early_stopping_patience: 5 # patience для early stopping, диапазон [2-20]
            lr_scheduler_patience: 10 # patience для ReduceLROnPlateau, диапазон [2-20]
            lr_scheduler_factor: 0.5 # factor для ReduceLROnPlateau, диапазон [0.1-0.9]
            scale_numerical: true # масштабировать ли числовые признаки: true/false
            scale_method: standard # метод масштабирования: standard, minmax, quantile, binning
            n_bins: 10 # количество бинов для binning, диапазон [2-100]
            device: cuda # устройство для обучения: cuda, cpu
            output_dim: 1 # размерность выхода (1 для binary/regression, n_classes для multiclass)
            verbose: true # выводить прогресс: true/false
            num_workers: 0 # количество worker-процессов, диапазон [0-8]
            random_state: 42 # seed для генерации случайных чисел, любое целое число
