common:
    name: "allstate-claims-severity"
    task: "regression" # binary, multiclass, regression
    metrics:
        - "mae"
        - "rmse"
        - "r2"
        - "mape"
    main_metric: "mae"
    model_dir: "/home/gleb/models" # пути сохранения обученных моделей
    skip_cols: []
    selected_models:
        - tabnet
        - lightautoml
        - random_forest
        - catboost
        - lightgbm
        - xgboost

split_data:
    test_rate: 0.2
    validation_rate: 0.2 # если не казан valid_path
    stratified_split: true # стратифицированное разбиение

sampling: # начальное сэмплирование данных
    use_sampling: false   # Если поставить false, то сэмплирование делать не будем
    train_sample_size: 100000 # размер тренировочной выборки
    validation_sample_size: 100000 # размер валидационной выборки
    sample_seed: 42 # seed для сэмплирования
    balanced_sampling: false # только для классификации
    positive_rate: 0.5 # только для бинарной классификации

train:
    verbose: true
    n_folds: 3 # количество фолдов для кросс-валидации

columns:
    all_features_file: "/www/dslib/spark_sota_modeling/dataset/allstate-claims-severity/features.txt"
    category_features_file: "/www/dslib/spark_sota_modeling/dataset/allstate-claims-severity/categorical_features.txt"
    target_col: "loss" # название целевой переменной
    index_cols: ["id"] # название колонки с id

data_source: # данные уже предобработаны и не содержат пропусков, категориальные признаки закодированы в целые числа
    train_path: "/www/dslib/spark_sota_modeling/dataset/allstate-claims-severity/train.parquet"
    valid_path: null

calibration:
    use_calibration: false # калибровка модели (только для бинарной классификации)
    calibration_type: "betacal" # betacal, isotonic

# Настройки специфичные для каждой модели
models:
    catboost:
        n_folds: 3
        use_custom_hyperparameters: false
        hyperparameters: # если use_custom_hyperparameters = true, то используем эти гиперпараметры
            depth: 10
            learning_rate: 0.01
            l2_leaf_reg: 3
            random_strength: 1
            bagging_temperature: 1
    lightgbm:
        n_folds: 3
        use_custom_hyperparameters: false
        hyperparameters:
            depth: 10
            learning_rate: 0.01
            l2_leaf_reg: 3
            random_strength: 1
            bagging_temperature: 1
    xgboost:
        n_folds: 3
        use_custom_hyperparameters: false
        hyperparameters:
            depth: 10
            learning_rate: 0.01
            l2_leaf_reg: 3
            random_strength: 1
            bagging_temperature: 1
    random_forest:
        n_folds: 3
        use_custom_hyperparameters: false
        hyperparameters:
            depth: 10
            learning_rate: 0.01
            l2_leaf_reg: 3
            random_strength: 1
    lightautoml:
        n_folds: 1
        use_custom_hyperparameters: false
    tabnet:
        n_folds: 1
        use_custom_hyperparameters: true
        hyperparameters:
            verbose: false
            dropout: 0.3
            lambda_sparse: 0.001
            learning_rate: 0.0015
            epochs: 200
            early_stopping_patience: 20
    cemlp:
        n_folds: 1
        use_custom_hyperparameters: true
        hyperparameters:
            cat_emb_dim: 4
            hidden_dims: [64, 32]
            activation: relu
            dropout: 0.1
            feature_dropout: 0.0
            normalization: batch
            virtual_batch_size: 128
            momentum: 0.9
            initialization: he_normal
            constant_value: 0.001
            leaky_relu_negative_slope: 0.1
            dynamic_emb_size: false
            min_emb_dim: 2
            max_emb_dim: 16
            batch_size: 1024
            epochs: 50
            learning_rate: 0.001
            weight_decay: 1e-5
            early_stopping_patience: 5
            lr_scheduler_patience: 10
            lr_scheduler_factor: 0.5
            scale_numerical: true
            scale_method: standard
            n_bins: 10
            device: cuda
            output_dim: 1
            verbose: true
            num_workers: 0
            random_state: 42
            use_self_attention: false
            num_attention_heads: 4
