common:
    task: "multiclass" # binary, multiclass, regression
    metrics:
        - "accuracy"
        - "f1;average=weighted"
        - "ap;average=macro"
        - "roc_auc;average=macro;multi_class=ovo"
    main_metric: "accuracy"
    model_dir: "/home/gleb/models" # пути сохранения обученных моделей
    skip_cols: []
    selected_models:
        - tabnet
        - catboost
        - lightgbm
        - xgboost
        - random_forest
        - lightautoml
        # - cemlp

split_data:
    test_rate: 0.2
    validation_rate: null # Установи null, чтобы не создавать valid_df
    stratified_split: true # стратифицированное разбиение
    split_seed: 42

sampling: # начальное сэмплирование данных
    use_sampling: false   # Если поставить false, то сэмплирование делать не будем
    train_sample_size: 100000 # размер тренировочной выборки
    validation_sample_size: 100000 # размер валидационной выборки
    sample_seed: 42 # seed для сэмплирования
    balanced_sampling: false # только для классификации
    positive_rate: 0.5 # только для бинарной классификации

train:
    verbose: true
    n_folds: 3 # количество фолдов для кросс-валидации

columns:
    all_features_file: "/www/dslib/spark_sota_modeling/dataset/forest-cover-type/features.txt"
    category_features_file: "/www/dslib/spark_sota_modeling/dataset/forest-cover-type/categorical_features.txt"
    target_col: "cover_type" # название целевой переменной
    index_cols: [] # название колонки с id

data_source: # данные уже предобработаны и не содержат пропусков, категориальные признаки закодированы в целые числа
    train_path: "/www/dslib/spark_sota_modeling/dataset/forest-cover-type/train.parquet"
    valid_path: null

calibration:
    use_calibration: false # калибровка модели (только для бинарной классификации)
    calibration_type: "betacal" # betacal, isotonic

# Настройки специфичные для каждой модели
models:
    catboost:
        n_folds: 3
        use_custom_hyperparameters: false
        hyperparameters: # если use_custom_hyperparameters = true, то используем эти гиперпараметры
            eval_metric: 'AUC'
            iterations: 1000
            early_stopping_rounds: 200
            thread_count: 4
            auto_class_weights: 'SqrtBalanced'
            random_seed: 42
            depth: 10
            min_data_in_leaf: 1
            l2_leaf_reg: 1.0
            border_count: 64
            rsm: 0.5
            subsample: 0.8
    lightgbm:
        n_folds: 3
        use_custom_hyperparameters: false
        hyperparameters:
            boosting_type: 'gbdt'
            num_boost_round: 1000
            metric: 'auc'
            n_jobs: 12
            verbosity: -1
            seed: 77
            max_depth: 16
            num_leaves: 63
            learning_rate: 0.06
            min_child_samples: 4
            colsample_bytree: 0.3
            subsample: 0.85
            subsample_freq: 10
            max_bin: 100
            min_child_weight: 1.0
            min_split_gain: 0.015
            reg_lambda: 5.6
            reg_alpha: 0.5
            early_stopping_rounds: 100
            silent: True
    xgboost:
        n_folds: 3
        use_custom_hyperparameters: false
        hyperparameters:
            n_estimators: 1000
            n_jobs: 16
            eval_metric: 'auc'
            early_stopping_rounds: 200
            tree_method: 'hist'
            max_depth: 10
            learning_rate: 0.03
            max_bin: 100
            subsample: 0.9
            colsample_bylevel: 0.5
    random_forest:
        n_folds: 3
        use_custom_hyperparameters: false
        hyperparameters:
            n_jobs: -1
            random_state: 5
            n_estimators: 1000
            max_depth: 100
            max_samples: 0.5
            bootstrap: true
            verbose: 0
    lightautoml:
        n_folds: 1
        use_custom_hyperparameters: false
    tabnet:
        n_folds: 1
        use_custom_hyperparameters: true
        hyperparameters:
            d_model: 16
            n_steps: 5
            decision_dim: 128
            n_shared: 1
            n_independent: 2
            dropout_glu: 0.01
            dropout_emb: 0.05
            gamma: 1.5
            lambda_sparse: 0.0001
            batch_size: 4096
            virtual_batch_size: 512
            momentum_att: 0.1
            momentum_glu: 0.01
            epochs: 2000
            learning_rate: 0.01
            early_stopping_patience: 25
            weight_decay: 1.0e-5
            reducelronplateau_patience: 5
            reducelronplateau_factor: 0.5
            verbose: false
            random_state: 42
    cemlp:
        n_folds: 1
        use_custom_hyperparameters: true
        hyperparameters:
            cat_emb_dim: 4
            hidden_dims: [64, 32]
            activation: relu
            dropout: 0.1
            feature_dropout: 0.0
            normalization: batch
            virtual_batch_size: 128
            momentum: 0.9
            initialization: he_normal
            constant_value: 0.001
            leaky_relu_negative_slope: 0.1
            dynamic_emb_size: false
            min_emb_dim: 2
            max_emb_dim: 16
            batch_size: 1024
            epochs: 50
            learning_rate: 0.001
            weight_decay: 1e-5
            early_stopping_patience: 5
            lr_scheduler_patience: 10
            lr_scheduler_factor: 0.5
            scale_numerical: true
            scale_method: standard
            n_bins: 10
            device: cuda
            output_dim: 1
            verbose: true
            num_workers: 0
            random_state: 42
            use_self_attention: false
            num_attention_heads: 4
